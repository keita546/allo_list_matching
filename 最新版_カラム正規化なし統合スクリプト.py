# -*- coding: utf-8 -*-
"""
ç´¯ç©ãƒªã‚¹ãƒˆçµ±åˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ï¼ˆé€±æ¬¡æ›´æ–°å°‚ç”¨ãƒ»èŠ±ç‹/ãƒ—ãƒ©ãƒãƒƒãƒˆè‡ªå‹•æŒ¯ã‚Šåˆ†ã‘ç‰ˆv5.1ï¼‰

ã€å¤‰æ›´ç‚¹ã€‘
- èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆãƒªã‚¹ãƒˆã‚’1ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
- ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ—ã§è‡ªå‹•æŒ¯ã‚Šåˆ†ã‘
- å„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã”ã¨ã«ç‹¬ç«‹ã—ãŸæœŸé–“ç®¡ç†

Author: HIBI KEITA
Version: 5.1
"""

import pandas as pd
from pathlib import Path
import tkinter as tk
from tkinter import filedialog, messagebox, simpledialog
from datetime import datetime


# ========================================================================
# ã‚«ãƒ©ãƒ å®šç¾©
# ========================================================================

# å¿…é ˆã‚«ãƒ©ãƒ ï¼ˆå…¥åŠ›ãƒ»å‡ºåŠ›å…±é€šï¼‰
REQUIRED_COLUMNS = ['æ—§JANã‚³ãƒ¼ãƒ‰', 'æ—§å•†å“å', 'æ–°JANã‚³ãƒ¼ãƒ‰', 'æ–°å•†å“å', 'æ–°JANå‚™è€ƒ']

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚«ãƒ©ãƒ 
METADATA_COLUMNS = ['ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹', 'æœŸé–“', 'å‡¦ç†æ—¥']

# Excelå‡ºåŠ›ç”¨ï¼ˆå…¨ã‚«ãƒ©ãƒ ï¼‰
OUTPUT_COLUMNS_EXCEL = REQUIRED_COLUMNS + METADATA_COLUMNS

# CSVå‡ºåŠ›ç”¨ï¼ˆã‚·ã‚¹ãƒ†ãƒ èª­ã¿è¾¼ã¿ç”¨ï¼‰
OUTPUT_COLUMNS_CSV = REQUIRED_COLUMNS


# ========================================================================
# ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
# ========================================================================

def load_file_flexible(file_path: str, sheet_name: str = 'ç¢ºå®š') -> pd.DataFrame:
    """CSV/TSV/Excelã‚’è‡ªå‹•åˆ¤åˆ¥ã—ã¦èª­ã¿è¾¼ã¿"""
    p = Path(file_path)
    ext = p.suffix.lower()
    
    print(f"ğŸ“– ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­: {p.name}")
    
    # Excel
    if ext in ['.xlsx', '.xls', '.xlsm']:
        try:
            df = pd.read_excel(file_path, sheet_name=sheet_name, engine='openpyxl', dtype=str)
            print(f"âœ… Excelèª­ã¿è¾¼ã¿æˆåŠŸï¼ˆã‚·ãƒ¼ãƒˆ: {sheet_name}ï¼‰")
            return df
        except Exception as e:
            raise ValueError(f"Excelèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    # CSV/TSV
    encodings = ['utf-8', 'shift_jis', 'cp932']
    delimiter_map = {'.csv': ',', '.tsv': '\t', '.txt': '\t'}
    
    if ext not in delimiter_map:
        raise ValueError(f"ã‚µãƒãƒ¼ãƒˆå¤–ã®æ‹¡å¼µå­: {ext}")
    
    delimiter = delimiter_map[ext]
    
    for encoding in encodings:
        try:
            df = pd.read_csv(file_path, encoding=encoding, delimiter=delimiter, 
                           on_bad_lines='skip', dtype=str)
            print(f"âœ… {ext}èª­ã¿è¾¼ã¿æˆåŠŸï¼ˆ{encoding}ï¼‰")
            return df
        except UnicodeDecodeError:
            continue
    
    raise UnicodeDecodeError(f"ã™ã¹ã¦ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§èª­ã¿è¾¼ã¿å¤±æ•—")


# ========================================================================
# ãƒ‡ãƒ¼ã‚¿å‡¦ç†
# ========================================================================

def normalize_columns(df: pd.DataFrame, file_type: str = 'matching') -> pd.DataFrame:
    """
    ã‚«ãƒ©ãƒ åã‚’æ¨™æº–å½¢å¼ã«æ­£è¦åŒ–
    
    Args:
        df: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        file_type: 'matching' or 'kao_planet'
    """
    print(f"ğŸ“ ã‚«ãƒ©ãƒ æ­£è¦åŒ–ä¸­: {file_type}")
    
    if file_type == 'kao_planet':
        # èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆã¯å›ºå®šå½¢å¼
        if set(REQUIRED_COLUMNS).issubset(set(df.columns)):
            print("âœ… æ—¢ã«æ¨™æº–å½¢å¼ã§ã™")
            return df
        else:
            raise ValueError(f"èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã«å¿…é ˆã‚«ãƒ©ãƒ ãŒã‚ã‚Šã¾ã›ã‚“: {set(REQUIRED_COLUMNS) - set(df.columns)}")
    
    elif file_type == 'matching':
        # ãƒãƒƒãƒãƒ³ã‚°çµæœã¯è‡ªå‹•å¤‰æ›
        print(f"  å…ƒã®ã‚«ãƒ©ãƒ : {list(df.columns)}")
        
        # ã‚«ãƒ©ãƒ åã®æ­£è¦åŒ–ãƒãƒƒãƒ”ãƒ³ã‚°
        rename_map = {}
        
        for col in df.columns:
            # æ—§JANã‚³ãƒ¼ãƒ‰ â†’ ãã®ã¾ã¾
            if 'æ—§JAN' in col and 'ã‚³ãƒ¼ãƒ‰' in col:
                rename_map[col] = 'æ—§JANã‚³ãƒ¼ãƒ‰'
            
            # æ—§å•†å“åï¼ˆæ¼¢å­—ï¼‰â€»æ¼¢å­—ãªã‘ã‚Œã°ã‚«ãƒŠ â†’ æ—§å•†å“å
            elif 'æ—§å•†å“å' in col:
                rename_map[col] = 'æ—§å•†å“å'
            
            # æ–°JANã‚³ãƒ¼ãƒ‰ â†’ ãã®ã¾ã¾
            elif 'æ–°JAN' in col and 'ã‚³ãƒ¼ãƒ‰' in col:
                rename_map[col] = 'æ–°JANã‚³ãƒ¼ãƒ‰'
            
            # æ–°å•†å“åï¼ˆæ¼¢å­—ï¼‰â€»æ¼¢å­—ãªã‘ã‚Œã°ã‚«ãƒŠ â†’ æ–°å•†å“å
            elif 'æ–°å•†å“å' in col:
                rename_map[col] = 'æ–°å•†å“å'
            
            # æ–°JANå‚™è€ƒ â†’ ãã®ã¾ã¾
            elif 'æ–°JANå‚™è€ƒ' in col or 'å‚™è€ƒ' in col:
                rename_map[col] = 'æ–°JANå‚™è€ƒ'
        
        print(f"  å¤‰æ›ãƒãƒƒãƒ—: {rename_map}")
        
        # ãƒªãƒãƒ¼ãƒ 
        df = df.rename(columns=rename_map)
        
        # å¿…é ˆã‚«ãƒ©ãƒ ãƒã‚§ãƒƒã‚¯ï¼ˆæ–°JANå‚™è€ƒä»¥å¤–ï¼‰
        required = ['æ—§JANã‚³ãƒ¼ãƒ‰', 'æ—§å•†å“å', 'æ–°JANã‚³ãƒ¼ãƒ‰', 'æ–°å•†å“å']
        missing = [col for col in required if col not in df.columns]
        
        if missing:
            raise ValueError(f"å¿…é ˆã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing}\nå…ƒã®ã‚«ãƒ©ãƒ : {list(df.columns)}")
        
        # æ–°JANå‚™è€ƒãŒãªã„å ´åˆã¯ç©ºåˆ—è¿½åŠ 
        if 'æ–°JANå‚™è€ƒ' not in df.columns:
            df['æ–°JANå‚™è€ƒ'] = ''
        
        print(f"  å¤‰æ›å¾Œ: {list(df.columns)}")
        print("âœ… ã‚«ãƒ©ãƒ æ­£è¦åŒ–å®Œäº†")
        return df
    
    else:
        raise ValueError(f"ä¸æ˜ãªfile_type: {file_type}")


def split_kao_planet_list(df: pd.DataFrame) -> tuple:
    """
    èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆãƒªã‚¹ãƒˆã‚’ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ—ã§æŒ¯ã‚Šåˆ†ã‘
    
    Args:
        df: èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆãƒªã‚¹ãƒˆï¼ˆãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ—ã‚ã‚Šï¼‰
    
    Returns:
        (kao_df, planet_df): èŠ±ç‹ãƒ‡ãƒ¼ã‚¿ã€ãƒ—ãƒ©ãƒãƒƒãƒˆãƒ‡ãƒ¼ã‚¿
    """
    print("ğŸ”€ èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æŒ¯ã‚Šåˆ†ã‘ä¸­...")
    
    if 'ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹' not in df.columns:
        raise ValueError("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # èŠ±ç‹ãƒ‡ãƒ¼ã‚¿
    kao_df = df[df['ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹'] == 'èŠ±ç‹'].copy()
    print(f"  èŠ±ç‹: {len(kao_df)}ä»¶")
    
    # ãƒ—ãƒ©ãƒãƒƒãƒˆãƒ‡ãƒ¼ã‚¿
    planet_df = df[df['ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹'] == 'ãƒ—ãƒ©ãƒãƒƒãƒˆ'].copy()
    print(f"  ãƒ—ãƒ©ãƒãƒƒãƒˆ: {len(planet_df)}ä»¶")
    
    # ãã®ä»–ï¼ˆè­¦å‘Šï¼‰
    other_df = df[~df['ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹'].isin(['èŠ±ç‹', 'ãƒ—ãƒ©ãƒãƒƒãƒˆ'])]
    if len(other_df) > 0:
        print(f"  âš ï¸ ãã®ä»–ï¼ˆç„¡è¦–ï¼‰: {len(other_df)}ä»¶")
        print(f"     ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å€¤: {other_df['ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹'].unique().tolist()}")
    
    print("âœ… æŒ¯ã‚Šåˆ†ã‘å®Œäº†")
    return kao_df, planet_df


def update_metadata(df: pd.DataFrame, period: str, note: str = '') -> pd.DataFrame:
    """
    ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã¯æ—¢ã«å…¥ã£ã¦ã„ã‚‹å‰æï¼‰
    
    Args:
        df: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ—ã‚ã‚Šï¼‰
        period: æœŸé–“ï¼ˆä¾‹: 25å¹´ä¸Šï¼‰
        note: æ–°JANå‚™è€ƒã«è¿½åŠ ã™ã‚‹æ–‡å­—åˆ—ï¼ˆç©ºã®å ´åˆã®ã¿ï¼‰
    """
    print(f"ğŸ“ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°ä¸­...")
    
    df = df.copy()
    
    # æœŸé–“ã¨å‡¦ç†æ—¥ã‚’æ›´æ–°
    df['æœŸé–“'] = period
    df['å‡¦ç†æ—¥'] = datetime.now().strftime('%Y-%m-%d')
    
    # æ–°JANå‚™è€ƒãŒç©ºã®å ´åˆã®ã¿noteã‚’å…¥ã‚Œã‚‹
    if note and 'æ–°JANå‚™è€ƒ' in df.columns:
        df.loc[df['æ–°JANå‚™è€ƒ'].isna() | (df['æ–°JANå‚™è€ƒ'] == ''), 'æ–°JANå‚™è€ƒ'] = note
    
    # ã‚«ãƒ©ãƒ é †ã‚’çµ±ä¸€
    df = df[OUTPUT_COLUMNS_EXCEL].copy()
    
    print(f"âœ… å‡¦ç†å®Œäº†: {len(df)}ä»¶")
    return df


def add_metadata(df: pd.DataFrame, source: str, period: str = '', note: str = '') -> pd.DataFrame:
    """
    ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ï¼ˆãƒãƒƒãƒãƒ³ã‚°ç”¨ï¼‰
    
    Args:
        df: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼ˆæ—¢ã«æ¨™æº–ã‚«ãƒ©ãƒ åï¼‰
        source: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ï¼ˆãƒãƒƒãƒãƒ³ã‚°ï¼‰
        period: æœŸé–“ï¼ˆä¾‹: 25å¹´ä¸Šï¼‰
        note: æ–°JANå‚™è€ƒã«è¿½åŠ ã™ã‚‹æ–‡å­—åˆ—ï¼ˆç©ºã®å ´åˆã®ã¿ï¼‰
    """
    print(f"ğŸ“ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ ä¸­: {source}")
    
    df = df.copy()
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
    df['ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹'] = source
    df['æœŸé–“'] = period
    df['å‡¦ç†æ—¥'] = datetime.now().strftime('%Y-%m-%d')
    
    # æ–°JANå‚™è€ƒãŒç©ºã®å ´åˆã®ã¿noteã‚’å…¥ã‚Œã‚‹
    if note and 'æ–°JANå‚™è€ƒ' in df.columns:
        df['æ–°JANå‚™è€ƒ'] = df['æ–°JANå‚™è€ƒ'].fillna(note).replace('', note)
    
    # ã‚«ãƒ©ãƒ é †ã‚’çµ±ä¸€
    df = df[OUTPUT_COLUMNS_EXCEL].copy()
    
    print(f"âœ… å‡¦ç†å®Œäº†: {len(df)}ä»¶")
    return df


def clean_jan_codes(df: pd.DataFrame) -> pd.DataFrame:
    """JANã‚³ãƒ¼ãƒ‰ã‚’13æ¡ã«çµ±ä¸€"""
    print("ğŸ§¹ JANã‚³ãƒ¼ãƒ‰ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ä¸­...")
    
    jan_cols = ['æ—§JANã‚³ãƒ¼ãƒ‰', 'æ–°JANã‚³ãƒ¼ãƒ‰']
    
    for col in jan_cols:
        if col in df.columns:
            df[col] = (df[col].astype(str)
                      .str.replace(r'\D+', '', regex=True)
                      .str.zfill(13)
                      .str[:13])
    
    print("âœ… ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°å®Œäº†")
    return df


def remove_specific_source_data(existing_df: pd.DataFrame, source_name: str, periods_to_keep: list) -> pd.DataFrame:
    """
    ç´¯ç©ãƒªã‚¹ãƒˆã‹ã‚‰ç‰¹å®šãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ï¼ˆèŠ±ç‹ or ãƒ—ãƒ©ãƒãƒƒãƒˆï¼‰ã®æŒ‡å®šæœŸé–“ä»¥å¤–ã‚’å‰Šé™¤
    
    Args:
        existing_df: æ—¢å­˜ã®ç´¯ç©ãƒªã‚¹ãƒˆ
        source_name: å‰Šé™¤å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åï¼ˆ'èŠ±ç‹' or 'ãƒ—ãƒ©ãƒãƒƒãƒˆ'ï¼‰
        periods_to_keep: ä¿æŒã™ã‚‹æœŸé–“ã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: ["25å¹´ä¸‹", "26å¹´ä¸Š"]ï¼‰
    """
    if existing_df.empty:
        return existing_df
    
    if 'ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹' not in existing_df.columns or 'æœŸé–“' not in existing_df.columns:
        print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹/æœŸé–“åˆ—ãŒãªã„ãŸã‚ã€å‰Šé™¤å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—")
        return existing_df
    
    print(f"ğŸ—‘ï¸ å¤ã„{source_name}ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ä¸­...")
    print(f"   ä¿æŒã™ã‚‹æœŸé–“: {periods_to_keep}")
    
    # å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ä»¥å¤–ã¯ãã®ã¾ã¾ä¿æŒ
    non_target = existing_df[existing_df['ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹'] != source_name]
    
    # å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã§ä¿æŒã™ã‚‹æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿
    target_keep = existing_df[
        (existing_df['ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹'] == source_name) &
        (existing_df['æœŸé–“'].isin(periods_to_keep))
    ]
    
    # å‰Šé™¤ã•ã‚Œã‚‹ä»¶æ•°ã‚’è¨ˆç®—
    target_all = existing_df[existing_df['ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹'] == source_name]
    removed_count = len(target_all) - len(target_keep)
    
    if removed_count > 0:
        print(f"   {source_name}å‰Šé™¤: {removed_count}ä»¶")
        print(f"   {source_name}ä¿æŒ: {len(target_keep)}ä»¶")
    
    result = pd.concat([non_target, target_keep], ignore_index=True)
    print(f"âœ… å‰Šé™¤å¾Œåˆè¨ˆ: {len(result)}ä»¶")
    
    return result


def merge_and_deduplicate(existing_df: pd.DataFrame, 
                          kao_df: pd.DataFrame, 
                          planet_df: pd.DataFrame,
                          matching_df: pd.DataFrame) -> pd.DataFrame:
    """
    4æ®µéšã®å„ªå…ˆé †ä½ä»˜ãçµ±åˆãƒ»é‡è¤‡å‰Šé™¤
    
    å„ªå…ˆé †ä½: ç´¯ç©ï¼ˆæ—¢å­˜ï¼‰ > èŠ±ç‹ > ãƒ—ãƒ©ãƒãƒƒãƒˆ > ãƒãƒƒãƒãƒ³ã‚°
    """
    print("\nğŸ“¦ ãƒ‡ãƒ¼ã‚¿çµ±åˆãƒ»é‡è¤‡å‰Šé™¤é–‹å§‹...")
    
    print(f"  ç´¯ç©ãƒ‡ãƒ¼ã‚¿: {len(existing_df)}ä»¶")
    print(f"  èŠ±ç‹ï¼ˆä»Šé€±ï¼‰: {len(kao_df)}ä»¶")
    print(f"  ãƒ—ãƒ©ãƒãƒƒãƒˆï¼ˆä»Šé€±ï¼‰: {len(planet_df)}ä»¶")
    print(f"  ãƒãƒƒãƒãƒ³ã‚°ï¼ˆä»Šé€±ï¼‰: {len(matching_df)}ä»¶")
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: ç´¯ç©å†…ã®èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆç”±æ¥ã®æ–°JANã‚’æŠ½å‡º
    existing_kao_planet_jans = set()
    if not existing_df.empty and 'ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹' in existing_df.columns:
        kao_planet_rows = existing_df[
            existing_df['ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹'].isin(['èŠ±ç‹', 'ãƒ—ãƒ©ãƒãƒƒãƒˆ'])
        ]
        existing_kao_planet_jans = set(kao_planet_rows['æ–°JANã‚³ãƒ¼ãƒ‰'].dropna())
        print(f"  ç´¯ç©å†…ã®èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆç”±æ¥JAN: {len(existing_kao_planet_jans)}ä»¶")
    
    # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒãƒƒãƒãƒ³ã‚°çµæœã‹ã‚‰ç´¯ç©å†…èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆé‡è¤‡ã‚’å‰Šé™¤
    if not matching_df.empty and existing_kao_planet_jans:
        before = len(matching_df)
        matching_df = matching_df[~matching_df['æ–°JANã‚³ãƒ¼ãƒ‰'].isin(existing_kao_planet_jans)].copy()
        removed = before - len(matching_df)
        if removed > 0:
            print(f"  âœ‚ï¸ ãƒãƒƒãƒãƒ³ã‚°â†’ç´¯ç©å†…èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆé‡è¤‡å‰Šé™¤: {removed}ä»¶")
    
    # ã‚¹ãƒ†ãƒƒãƒ—3: ä»Šé€±ã®èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆã¨ãƒãƒƒãƒãƒ³ã‚°ã®é‡è¤‡å‰Šé™¤
    new_kao_planet_df = pd.concat([kao_df, planet_df], ignore_index=True)
    
    if not new_kao_planet_df.empty and not matching_df.empty:
        kao_planet_old_jans = set(new_kao_planet_df['æ—§JANã‚³ãƒ¼ãƒ‰'].dropna())
        kao_planet_new_jans = set(new_kao_planet_df['æ–°JANã‚³ãƒ¼ãƒ‰'].dropna())
        
        before = len(matching_df)
        matching_df = matching_df[~matching_df['æ–°JANã‚³ãƒ¼ãƒ‰'].isin(kao_planet_new_jans)].copy()
        matching_df = matching_df[~matching_df['æ—§JANã‚³ãƒ¼ãƒ‰'].isin(kao_planet_old_jans)].copy()
        removed = before - len(matching_df)
        if removed > 0:
            print(f"  âœ‚ï¸ ãƒãƒƒãƒãƒ³ã‚°â†’ä»Šé€±èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆé‡è¤‡å‰Šé™¤: {removed}ä»¶")
    
    # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ‡ãƒ¼ã‚¿çµåˆï¼ˆå„ªå…ˆé †ä½é †ï¼‰
    all_data = pd.concat([existing_df, kao_df, planet_df, matching_df], ignore_index=True)
    print(f"  çµ±åˆå¾Œ: {len(all_data)}ä»¶")
    
    # ã‚¹ãƒ†ãƒƒãƒ—5: æ–°JANã§é‡è¤‡å‰Šé™¤ï¼ˆå…ˆé ­å„ªå…ˆï¼‰
    before = len(all_data)
    all_data = all_data.drop_duplicates(subset=['æ–°JANã‚³ãƒ¼ãƒ‰'], keep='first')
    removed = before - len(all_data)
    if removed > 0:
        print(f"  ğŸ—‘ï¸ æ–°JANé‡è¤‡å‰Šé™¤: {removed}ä»¶")
    
    # ã‚¹ãƒ†ãƒƒãƒ—6: æ—§JAN=æ–°JANã®åŒä¸€JANã‚’å‰Šé™¤
    before = len(all_data)
    all_data = all_data[all_data['æ—§JANã‚³ãƒ¼ãƒ‰'] != all_data['æ–°JANã‚³ãƒ¼ãƒ‰']].copy()
    removed = before - len(all_data)
    if removed > 0:
        print(f"  ğŸ”„ åŒä¸€JANå‰Šé™¤: {removed}ä»¶")
    
    print(f"  âœ… æœ€çµ‚ä»¶æ•°: {len(all_data)}ä»¶")
    return all_data


# ========================================================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ========================================================================

def main():
    print("=" * 60)
    print("ç´¯ç©ãƒªã‚¹ãƒˆçµ±åˆãƒ—ãƒ­ã‚°ãƒ©ãƒ  - é€±æ¬¡æ›´æ–°ï¼ˆv5.1ãƒ»èŠ±ç‹/ãƒ—ãƒ©ãƒãƒƒãƒˆè‡ªå‹•æŒ¯ã‚Šåˆ†ã‘ç‰ˆï¼‰")
    print("=" * 60)
    
    # ========== ã‚¹ãƒ†ãƒƒãƒ—1: ç´¯ç©ãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿ ==========
    print("\nã€ã‚¹ãƒ†ãƒƒãƒ—1ã€‘ç´¯ç©ãƒªã‚¹ãƒˆã®èª­ã¿è¾¼ã¿")
    
    root = tk.Tk()
    root.withdraw()
    
    existing_df = pd.DataFrame()
    
    if messagebox.askyesno("ç´¯ç©ãƒªã‚¹ãƒˆ", "å‰é€±ã®ç´¯ç©ãƒªã‚¹ãƒˆãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ\nï¼ˆåˆå›ã¯ã€Œã„ã„ãˆã€ï¼‰"):
        existing_path = filedialog.askopenfilename(
            title="å‰é€±ã®ç´¯ç©ãƒªã‚¹ãƒˆã‚’é¸æŠ",
            filetypes=[("Excel/CSV", "*.xlsx *.csv"), ("ã™ã¹ã¦", "*.*")]
        )
        
        if existing_path:
            try:
                existing_df = load_file_flexible(existing_path)
                existing_df = clean_jan_codes(existing_df)
                print(f"âœ… ç´¯ç©ãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿: {len(existing_df)}ä»¶")
            except Exception as e:
                messagebox.showerror("ã‚¨ãƒ©ãƒ¼", f"ç´¯ç©ãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿å¤±æ•—:\n{e}")
                root.destroy()
                return
    else:
        print("ğŸ“‚ æ–°è¦ä½œæˆãƒ¢ãƒ¼ãƒ‰")
    
    root.destroy()
    
    # ========== ã‚¹ãƒ†ãƒƒãƒ—2: ãƒãƒƒãƒãƒ³ã‚°çµæœèª­ã¿è¾¼ã¿ ==========
    print("\nã€ã‚¹ãƒ†ãƒƒãƒ—2ã€‘ãƒãƒƒãƒãƒ³ã‚°çµæœã®èª­ã¿è¾¼ã¿")
    
    root = tk.Tk()
    root.withdraw()
    
    messagebox.showinfo("é¸æŠ", "ä»Šé€±ã®ãƒãƒƒãƒãƒ³ã‚°çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
    
    matching_path = filedialog.askopenfilename(
        title="ãƒãƒƒãƒãƒ³ã‚°çµæœã‚’é¸æŠ",
        filetypes=[("Excel/CSV", "*.xlsx *.csv *.tsv"), ("ã™ã¹ã¦", "*.*")]
    )
    
    root.destroy()
    
    if not matching_path:
        messagebox.showwarning("ã‚­ãƒ£ãƒ³ã‚»ãƒ«", "ãƒãƒƒãƒãƒ³ã‚°çµæœãŒé¸æŠã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    try:
        matching_df = load_file_flexible(matching_path)
        matching_df = normalize_columns(matching_df, file_type='matching')
        matching_df = add_metadata(
            matching_df, 
            source='ãƒãƒƒãƒãƒ³ã‚°',
            note=Path(matching_path).name
        )
        matching_df = clean_jan_codes(matching_df)
        print(f"âœ… ãƒãƒƒãƒãƒ³ã‚°çµæœèª­ã¿è¾¼ã¿: {len(matching_df)}ä»¶")
    except Exception as e:
        messagebox.showerror("ã‚¨ãƒ©ãƒ¼", f"ãƒãƒƒãƒãƒ³ã‚°çµæœèª­ã¿è¾¼ã¿å¤±æ•—:\n{e}")
        return
    
    # ========== ã‚¹ãƒ†ãƒƒãƒ—3: èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿ ==========
    print("\nã€ã‚¹ãƒ†ãƒƒãƒ—3ã€‘èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆãƒªã‚¹ãƒˆã®èª­ã¿è¾¼ã¿")
    
    root = tk.Tk()
    root.withdraw()
    
    kao_df = pd.DataFrame()
    planet_df = pd.DataFrame()
    
    choice = messagebox.askquestion(
        "èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆãƒªã‚¹ãƒˆ", 
        "ä»Šé€±ã€èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆãƒªã‚¹ãƒˆã‚’æ›´æ–°ã—ã¾ã™ã‹ï¼Ÿ\n\n"
        "ã€Œã¯ã„ã€â†’ æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿\n"
        "ã€Œã„ã„ãˆã€â†’ ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒï¼‰"
    )
    
    if choice == 'yes':
        # ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
        kao_planet_path = filedialog.askopenfilename(
            title="èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆãƒªã‚¹ãƒˆã‚’é¸æŠ",
            filetypes=[("Excel/CSV", "*.xlsx *.csv"), ("ã™ã¹ã¦", "*.*")]
        )
        
        if not kao_planet_path:
            messagebox.showwarning("ã‚­ãƒ£ãƒ³ã‚»ãƒ«", "èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆãƒªã‚¹ãƒˆãŒé¸æŠã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        else:
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
                kao_planet_df = load_file_flexible(kao_planet_path)
                kao_planet_df = normalize_columns(kao_planet_df, file_type='kao_planet')
                kao_planet_df = clean_jan_codes(kao_planet_df)
                
                # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ—ãƒã‚§ãƒƒã‚¯
                if 'ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹' not in kao_planet_df.columns:
                    raise ValueError("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
                # èŠ±ç‹ã¨ãƒ—ãƒ©ãƒãƒƒãƒˆã«æŒ¯ã‚Šåˆ†ã‘
                kao_df, planet_df = split_kao_planet_list(kao_planet_df)
                
                # èŠ±ç‹ã®æœŸé–“è¨­å®š
                if not kao_df.empty:
                    kao_period = simpledialog.askstring(
                        "èŠ±ç‹æœŸé–“å…¥åŠ›",
                        f"èŠ±ç‹ãƒªã‚¹ãƒˆã®æœŸé–“ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„\nï¼ˆä¾‹: 25å¹´ä¸‹,26å¹´ä¸Šï¼‰\n\n"
                        f"èª­ã¿è¾¼ã‚“ã èŠ±ç‹ãƒ‡ãƒ¼ã‚¿: {len(kao_df)}ä»¶",
                        initialvalue="25å¹´ä¸‹,26å¹´ä¸Š"
                    )
                    
                    if not kao_period:
                        kao_period = datetime.now().strftime('%Yå¹´')
                    
                    # ä¿æŒã™ã‚‹æœŸé–“
                    kao_keep_periods_str = simpledialog.askstring(
                        "èŠ±ç‹ä¿æŒæœŸé–“",
                        "ç´¯ç©ã‹ã‚‰ä¿æŒã™ã‚‹èŠ±ç‹ã®æœŸé–“ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ›\n"
                        "ï¼ˆä¾‹: 25å¹´ä¸‹,26å¹´ä¸Šï¼‰\n\n"
                        "â€»ã“ã®æœŸé–“ä»¥å¤–ã®èŠ±ç‹ãƒ‡ãƒ¼ã‚¿ã¯å‰Šé™¤ã•ã‚Œã¾ã™\n"
                        "â€»ç©ºæ¬„ã§èŠ±ç‹ãƒ‡ãƒ¼ã‚¿å…¨å‰Šé™¤ã—ã¦ã‹ã‚‰æ–°è¦è¿½åŠ ",
                        initialvalue=kao_period
                    )
                    
                    if kao_keep_periods_str:
                        kao_periods_to_keep = [p.strip() for p in kao_keep_periods_str.split(',')]
                    else:
                        kao_periods_to_keep = []
                    
                    # å¤ã„èŠ±ç‹ãƒ‡ãƒ¼ã‚¿å‰Šé™¤
                    existing_df = remove_specific_source_data(existing_df, 'èŠ±ç‹', kao_periods_to_keep)
                    
                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
                    kao_df = update_metadata(kao_df, kao_period, Path(kao_planet_path).name)
                    print(f"âœ… èŠ±ç‹ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Œäº†: {len(kao_df)}ä»¶")
                
                # ãƒ—ãƒ©ãƒãƒƒãƒˆã®æœŸé–“è¨­å®š
                if not planet_df.empty:
                    planet_period = simpledialog.askstring(
                        "ãƒ—ãƒ©ãƒãƒƒãƒˆæœŸé–“å…¥åŠ›",
                        f"ãƒ—ãƒ©ãƒãƒƒãƒˆãƒªã‚¹ãƒˆã®æœŸé–“ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„\nï¼ˆä¾‹: 25å¹´ä¸Š,25å¹´ä¸‹ï¼‰\n\n"
                        f"èª­ã¿è¾¼ã‚“ã ãƒ—ãƒ©ãƒãƒƒãƒˆãƒ‡ãƒ¼ã‚¿: {len(planet_df)}ä»¶",
                        initialvalue="25å¹´ä¸Š,25å¹´ä¸‹"
                    )
                    
                    if not planet_period:
                        planet_period = datetime.now().strftime('%Yå¹´')
                    
                    # ä¿æŒã™ã‚‹æœŸé–“
                    planet_keep_periods_str = simpledialog.askstring(
                        "ãƒ—ãƒ©ãƒãƒƒãƒˆä¿æŒæœŸé–“",
                        "ç´¯ç©ã‹ã‚‰ä¿æŒã™ã‚‹ãƒ—ãƒ©ãƒãƒƒãƒˆã®æœŸé–“ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ›\n"
                        "ï¼ˆä¾‹: 25å¹´ä¸Š,25å¹´ä¸‹ï¼‰\n\n"
                        "â€»ã“ã®æœŸé–“ä»¥å¤–ã®ãƒ—ãƒ©ãƒãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã¯å‰Šé™¤ã•ã‚Œã¾ã™\n"
                        "â€»ç©ºæ¬„ã§ãƒ—ãƒ©ãƒãƒƒãƒˆãƒ‡ãƒ¼ã‚¿å…¨å‰Šé™¤ã—ã¦ã‹ã‚‰æ–°è¦è¿½åŠ ",
                        initialvalue=planet_period
                    )
                    
                    if planet_keep_periods_str:
                        planet_periods_to_keep = [p.strip() for p in planet_keep_periods_str.split(',')]
                    else:
                        planet_periods_to_keep = []
                    
                    # å¤ã„ãƒ—ãƒ©ãƒãƒƒãƒˆãƒ‡ãƒ¼ã‚¿å‰Šé™¤
                    existing_df = remove_specific_source_data(existing_df, 'ãƒ—ãƒ©ãƒãƒƒãƒˆ', planet_periods_to_keep)
                    
                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
                    planet_df = update_metadata(planet_df, planet_period, Path(kao_planet_path).name)
                    print(f"âœ… ãƒ—ãƒ©ãƒãƒƒãƒˆãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Œäº†: {len(planet_df)}ä»¶")
                
            except Exception as e:
                messagebox.showerror("ã‚¨ãƒ©ãƒ¼", f"èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿å¤±æ•—:\n{e}")
                root.destroy()
                return
    else:
        print("ğŸ“‚ èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆãƒªã‚¹ãƒˆãªã—ï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ä¿æŒï¼‰")
    
    root.destroy()
    
    # ========== ã‚¹ãƒ†ãƒƒãƒ—4: å‡ºåŠ›å…ˆé¸æŠ ==========
    print("\nã€ã‚¹ãƒ†ãƒƒãƒ—4ã€‘å‡ºåŠ›å…ˆã®é¸æŠ")
    
    root = tk.Tk()
    root.withdraw()
    
    output_dir = filedialog.askdirectory(title="ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠ")
    
    root.destroy()
    
    if not output_dir:
        messagebox.showwarning("ã‚­ãƒ£ãƒ³ã‚»ãƒ«", "ä¿å­˜å…ˆãŒé¸æŠã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    output_dir = Path(output_dir)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_csv = output_dir / f"ç´¯ç©_å·®ã—æ›¿ãˆãƒªã‚¹ãƒˆ_{timestamp}.csv"
    output_excel = output_dir / f"ç´¯ç©_å·®ã—æ›¿ãˆãƒªã‚¹ãƒˆ_{timestamp}.xlsx"
    latest_csv = output_dir / "ç´¯ç©_å·®ã—æ›¿ãˆãƒªã‚¹ãƒˆ_æœ€æ–°.csv"
    latest_excel = output_dir / "ç´¯ç©_å·®ã—æ›¿ãˆãƒªã‚¹ãƒˆ_æœ€æ–°.xlsx"
    
    # ========== ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ‡ãƒ¼ã‚¿çµ±åˆ ==========
    print("\nã€ã‚¹ãƒ†ãƒƒãƒ—5ã€‘ãƒ‡ãƒ¼ã‚¿çµ±åˆãƒ»é‡è¤‡å‰Šé™¤")
    
    final_df = merge_and_deduplicate(existing_df, kao_df, planet_df, matching_df)
    
    # ========== ã‚¹ãƒ†ãƒƒãƒ—6: ä¿å­˜ ==========
    print("\nã€ã‚¹ãƒ†ãƒƒãƒ—6ã€‘ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜")
    
    try:
        # CSVï¼ˆã‚·ã‚¹ãƒ†ãƒ èª­ã¿è¾¼ã¿ç”¨: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰
        print(f"ğŸ’¾ CSVä¿å­˜ä¸­ï¼ˆã‚·ã‚¹ãƒ†ãƒ ç”¨ãƒ»cp932ï¼‰: {output_csv.name}")
        final_df[OUTPUT_COLUMNS_CSV].to_csv(output_csv, index=False, encoding='cp932', errors='replace')
        final_df[OUTPUT_COLUMNS_CSV].to_csv(latest_csv, index=False, encoding='cp932', errors='replace')
        
        # Excelï¼ˆç®¡ç†ç”¨: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚ã‚Šï¼‰
        print(f"ğŸ’¾ Excelä¿å­˜ä¸­ï¼ˆç®¡ç†ç”¨ãƒ»å…¨ã‚«ãƒ©ãƒ ï¼‰: {output_excel.name}")
        final_df[OUTPUT_COLUMNS_EXCEL].to_excel(output_excel, index=False, engine='openpyxl')
        final_df[OUTPUT_COLUMNS_EXCEL].to_excel(latest_excel, index=False, engine='openpyxl')
        
        print("âœ… ä¿å­˜å®Œäº†")
    except Exception as e:
        messagebox.showerror("ã‚¨ãƒ©ãƒ¼", f"ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å¤±æ•—:\n{e}")
        return
    
    # ========== å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ ==========
    source_counts = final_df['ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹'].value_counts().to_dict() if 'ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹' in final_df.columns else {}
    
    # æœŸé–“åˆ¥ã®é›†è¨ˆã‚‚è¿½åŠ 
    period_summary = ""
    if 'ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹' in final_df.columns and 'æœŸé–“' in final_df.columns:
        period_summary = "\nã€ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹Ã—æœŸé–“åˆ¥ã€‘\n"
        for source in ['èŠ±ç‹', 'ãƒ—ãƒ©ãƒãƒƒãƒˆ', 'ãƒãƒƒãƒãƒ³ã‚°']:
            source_data = final_df[final_df['ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹'] == source]
            if not source_data.empty:
                period_counts = source_data['æœŸé–“'].value_counts().to_dict()
                period_summary += f"  {source}:\n"
                for period, count in period_counts.items():
                    period_summary += f"    - {period}: {count}ä»¶\n"
    
    summary = f"""
ğŸ‰ çµ±åˆå‡¦ç†å®Œäº†ï¼

ã€ç´¯ç©ãƒ‡ãƒ¼ã‚¿ã€‘
ç·ä»¶æ•°: {len(final_df)}ä»¶

ã€ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¥ã€‘
{chr(10).join([f'  {k}: {v}ä»¶' for k, v in source_counts.items()])}
{period_summary}
ã€ä¿å­˜å…ˆã€‘
ğŸ“ {output_dir}

ã€ãƒ•ã‚¡ã‚¤ãƒ«ã€‘
- CSVï¼ˆã‚·ã‚¹ãƒ†ãƒ ç”¨ï¼‰: {output_csv.name}
- Excelï¼ˆç®¡ç†ç”¨ï¼‰: {output_excel.name}
- ç´¯ç©_å·®ã—æ›¿ãˆãƒªã‚¹ãƒˆ_æœ€æ–°.csv/xlsx
"""
    
    print(summary)
    messagebox.showinfo("å®Œäº†", summary)


# ========================================================================
# å®Ÿè¡Œ
# ========================================================================

if __name__ == "__main__":
    main()