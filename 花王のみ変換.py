# -*- coding: utf-8 -*-
"""
花王・プラネットの商品差し替えリスト作成スクリプト（構造最適化版）
author :HibiKeita
"""

from pathlib import Path
import pandas as pd

# --- 0. 設定 ---
# スクリプトのルートディレクトリを指定します。
# なぜここにまとめるかというと、全てのファイルの場所の基準になるからです。フォルダ構成が変わってもここだけ直せば済むように、一元管理しています。
ROOT_DIR = Path("C:/Users/337475/Box/LTS様/■アルゴリズム関連/依頼事項")

# 花王の新規品・廃止品リストのファイルパスをリストでまとめています。
# なぜリストにするかというと、複数のファイルをまとめて同じ処理（読み込み・結合）を効率的に行いたいからです。
Kao_PATHS = [
    ROOT_DIR / "花王新規品廃止品リスト/2025年秋/2025年秋新製品廃止品対比表_バーコードなし（0520).xlsm",
    ROOT_DIR / "花王新規品廃止品リスト/2025年春/2025年春新製品廃止品対比表_バーコードなし（1225).xlsm",
    ROOT_DIR / "花王新規品廃止品リスト/2024年秋/2024年秋新製品・廃止品対比表_バーコードなし（0705）.xlsm"
]

# プラネットの新規品・廃止品リストのファイルパスを辞書で管理しています。
# なぜ辞書にするかというと、期間（例: "2024秋"）とファイルの種類（"new", "disc"）でファイルを整理することで、アクセス性を高め、コード内でのファイルの参照を分かりやすくするためです。
Planet_PATHS = {
    "2024秋": {
        "new": ROOT_DIR / "プラネット新規品廃止品リスト/2024年秋/新製品リスト_20241128_085316.xlsx",
        "disc": ROOT_DIR / "プラネット新規品廃止品リスト/2024年秋/廃番品リスト_20241128_085150.xlsx",
    },
    "2025春": {
        "new": ROOT_DIR / "プラネット新規品廃止品リスト/2025年春/新製品リスト_20250128_134956.xlsx",
        "disc": ROOT_DIR / "プラネット新規品廃止品リスト/2025年春/廃番品リスト_20250128_135031.xlsx",
    },
    "2025秋": {
        # ここは実際のファイル名に修正が必要です。
        "new": ROOT_DIR / "プラネット新規品廃止品リスト/2025年秋/新製品リスト_2025秋版_仮.xlsx",
        "disc": ROOT_DIR / "プラネット新規品廃止品リスト/2025年秋/廃番品リスト_2025秋版_仮.xlsx",
    },
}

# --- 1. 花王データ読み込み関数 ---
# 花王のExcelファイルを読み込み、必要な列を抽出して、備考列を追加する関数です。
# なぜ備考列を追加するかというと、最終的な結合データで、どの情報がどのファイルから来たのかを一目で分かるようにするためです。
def load_kao(path):
    # Excelファイルを読み込んでいます。usecolsで必要な列だけを選び、skiprowsで最初の5行を飛ばしています。
    # なぜ特定の列だけ選んで特定の行を飛ばすかというと、ファイルの形式に合わせて、必要なデータだけを効率的に取り出すためです。
    df = pd.read_excel(path, usecols=[6, 14, 41, 43], skiprows=5, header=None)
    # 読み込んだ列に分かりやすい名前を付けています。
    # なぜ名前を付けるかというと、後でコードを読む時やデータを確認する時に、どの列が何を示しているか一目で分かるようにするためです。
    df.columns = ['新商品名', '新JAN', '旧JAN', '旧商品名']
    # 旧JANと新JANのどちらかが欠損している行は除外しています。
    # なぜ欠損値を除外するかというと、JANコードがないと「どの商品がどの商品に差し替わったか」が特定できないため、分析に不要なデータとなるからです。
    df = df.dropna(subset=['旧JAN', '新JAN'])[['旧JAN', '旧商品名', '新JAN', '新商品名']]

    # 元のファイル名を「備考」列として追加しています。
    # なぜファイル名を追加するかというと、後で重複データなどをチェックする時に、どのファイル由来のデータか分かると追跡が便利だからです。
    df['備考'] = path.name # path.nameでファイル名のみを取得しています。
    return df

# --- 2. プラネットクレンジング関数 ---
# プラネットのデータをクリーンアップするための関数です。
# 花王と違って、プラネットは新規品と廃番品でファイルの構造が異なるため、それに対応するための処理をまとめています。
def clean_planet(df, mode):
    # データフレームの列名に含まれる全角の「ＪＡＮ」を半角の「JAN」に統一しています。
    # なぜ統一するかというと、列名が表記ゆれしていると、後の処理で参照エラーの原因となるため、標準化してエラーを未然に防ぐためです。
    df.columns = df.columns.str.replace('ＪＡＮ', 'JAN')
    
    if mode == 'discontinue':
        # 廃番品のデータを処理する場合です。'JANコード'と'廃番予定品'のどちらかが欠損している行を除外しています。
        # なぜ除外するかというと、廃番のJANコードや商品名が特定できないと、その情報が利用できないためです。
        df = df.dropna(subset=['JANコード', '廃番予定品'])
        # 必要な列だけを選び、列名を分かりやすく変更しています。
        # こうすることで、後の結合処理で花王のデータと列名が整合するようにしています。
        return df.rename(columns={'JANコード': '旧JAN', '廃番予定品': '旧商品名'})[['旧JAN', '旧商品名']]
    else: # mode == 'new'
        # 新規品のデータを処理する場合です。
        # 'JANコード', '旧JANコード', '商品名全角' のいずれかが欠損している行を除外しています。
        # なぜ除外するかというと、これらの情報が揃っていないと、新規品のJANコードや旧JANコード、商品名が特定できないためです。
        df = df.dropna(subset=['JANコード', '旧JANコード', '商品名全角'])
        # 必要な列だけを選び、列名を分かりやすく変更しています。
        # 新規品の場合は、旧JANと新JAN、新商品名の対応が必要なため、それらが明確になるようにしています。
        return df.rename(columns={'旧JANコード': '旧JAN', 'JANコード': '新JAN', '商品名全角': '新商品名'})[
            ['旧JAN', '新JAN', '新商品名']
        ]

# --- 3. 純粋新規品抽出 ---
# 新しい商品（新JAN）が、古い商品のリスト（旧JANリスト）に存在しない場合だけを抽出する関数です。
# これが「純粋な新規品」を特定するためのコアな処理となります。
def extract_unmatched(new_df, old_df):
    # new_df（新規品リスト）の中から、その「新JAN」がold_df（廃番品リスト）の「旧JAN」に含まれていない行だけを選び出しています。
    # なぜ `~new_df['新JAN'].isin(old_df['旧JAN'])` を使うかというと、効率的に大量のデータの中から「含まれないもの」をフィルタリングできるからです。
    add = new_df[~new_df['新JAN'].isin(old_df['旧JAN'])].copy()
    # 新しく追加された商品には「旧商品名」がないため、その列を空文字で埋めています。
    # なぜ空文字で埋めるかというと、後の結合処理で列の数が合わなかったり、データ型がバラバラになったりするのを防ぐためです。
    add['旧商品名'] = ''
    return add[['旧JAN', '旧商品名', '新JAN', '新商品名']]

# --- 4. クレンジング前除外処理 ---
# プラネットのデータから、花王の関連商品を除外する関数です。
# なぜ除外するかというと、花王のデータは別に処理しているため、重複を避けるためです。これはMECE（漏れなくダブりなく）の原則に基づいています。
def exclude_kao(df, is_kao_col):
    # 'メーカーコード'または'メーカー'列が'4901301'で始まる、または'花王株式会社'を含む行を除外しています。
    # なぜastype(str)にするかというと、列のデータ型が数値型だった場合でも文字列として処理できるようにし、処理の安定性を確保するためです。
    return df[~df[is_kao_col].astype(str).str.startswith('4901301') & ~df[is_kao_col].astype(str).str.contains('花王株式会社')]

# --- 5. プラネット差し替えリスト生成 ---
# プラネットの各期間のデータを処理して、差し替えリストを生成する関数です。
# なぜループを使うかというと、各期間で同じような処理を何度も書かずに済むように、自動化してコードの可読性を高めるためです。
def process_planet_diff():
    result = [] # 各期間の処理結果を一時的に格納するリストです。
    for season, paths in Planet_PATHS.items():
        # 新規品と廃番品のExcelファイルを読み込んでいます。
        new_df = pd.read_excel(paths['new'])
        disc_df = pd.read_excel(paths['disc'])
        
        # プラネットのファイルにも「備考」列を追加しています。
        # なぜファイル名を追加するかというと、後で重複データなどをチェックする時に、どのファイル由来のデータか分かると便利だからです。
        new_df['備考'] = paths['new'].name
        disc_df['備考'] = paths['disc'].name

        # 花王関連のデータを除外しています。
        new_df = exclude_kao(new_df, 'メーカーコード')
        disc_df = exclude_kao(disc_df, 'メーカー')
        
        # プラネットのデータをクリーンアップしています。
        new_clean = clean_planet(new_df, 'new')
        disc_clean = clean_planet(disc_df, 'discontinue')
        
        # 純粋な新規品を抽出しています。
        diff = extract_unmatched(new_clean, disc_clean)

        # 純粋新規品リスト（diff）に、元の新規品データ（new_df）から取得した備考列を結合しています。
        # なぜ結合し直すかというと、`clean_planet`関数で列が絞られた結果、備考列が一度失われているためです。元のファイル名情報を再度紐づけることで、「どのファイルの新規品が純粋新規と判断されたか」を明確にしています。
        diff_with_notes = pd.merge(diff, new_df[['JANコード', '備考']], left_on='新JAN', right_on='JANコード', how='left')
        diff_with_notes = diff_with_notes.drop(columns='JANコード').rename(columns={'備考': '新JAN備考'})

        # 廃番品（旧JAN）の備考も必要であれば、同様にmergeすれば結合できます。
        
        result.append(diff_with_notes) # 処理結果をリストに追加しています。
        
    # 全ての期間の処理結果を一つに結合しています。
    return pd.concat(result, ignore_index=True)

# --- 6. クリーンアップ処理 ---
# 最終的なデータフレームを整形する関数です。
# JANコードのクリーニングや、商品名の欠損値処理、重複行の削除などを行っています。
def finalize(df):
    # 列名を統一しています。
    # なぜ統一するかというと、最終的な出力CSV/Excelの可読性を高め、他のシステムとの連携もしやすくするためです。
    df = df.rename(columns={'旧JAN': '旧JANコード', '新JAN': '新JANコード'})
    
    # JANコード列をクリーンアップしています。
    # 文字列変換 -> 数字以外を除去 -> 空文字を欠損値に -> nullableな整数型に変換、という一連の処理を行っています。
    # なぜこの手間をかけるかというと、JANコードは数字ですが、入力過程やExcel読み込みでハイフンやスペースが混入することがあるため、統一された数値データとして扱えるようにするためです。
    for col in ['旧JANコード', '新JANコード']:
        df[col] = (df[col].astype(str)                                  # まずは文字列に変換します。これは、`str.replace`を使うためです。
                           .str.replace(r'\D+', '', regex=True)         # 正規表現`\D+`を使って数字以外の文字を全て空文字に置き換えています。なぜ正規表現を使うかというと、様々な非数字文字を一括で効率的に除去できるからです。
                           .replace('', pd.NA)                           # 数字以外を除去した結果、空になった文字列（''）をPandasの欠損値`pd.NA`に変換します。なぜかというと、空文字ではなく欠損値として扱うことで後の数値処理がスムーズになるためです。
                           .astype('Int64'))                             # 最後に、欠損値を含めることができる整数型`Int64`に変換しています。なぜ`Int64`かというと、Python標準の`int`型は欠損値を扱えませんが、Pandasの`Int64`は`pd.NA`を扱えるため、データ型を統一しつつ欠損値に対応するためです。

    # 商品名の空文字を「該当文字列なし」に置換しています。
    # なぜ置換するかというと、空白のままだとユーザーがデータを見た時に分かりにくく、情報がないことを明示的に伝えるためです。
    df['旧商品名'] = df['旧商品名'].replace('', '該当文字列なし')
    df['新商品名'] = df['新商品名'].replace('', '該当文字列なし')

    # 旧JANコードと新JANコードが同じ行は除外しています。
    # なぜ除外するかというと、差し替えリストの目的は「何が何に変わったか」を把握することであるため、同じ商品コードの行は意味がないからです。
    return df[df['旧JANコード'] != df['新JANコード']]

# --- 7. メイン処理 ---
# スクリプトの主要な処理の流れを管理する関数です。
# 各関数を呼び出して、データ処理の全体を統括しています。
def main():
    # 花王の全てのリストを読み込み、結合しています。
    # load_kao関数で既に備考列が追加されているため、どのファイルからのデータか追跡可能です。
    kao_df = pd.concat([load_kao(p) for p in Kao_PATHS], ignore_index=True)

    # 最終的なデータクリーンアップと整形を行っています。
    final_df = finalize(kao_df)
    
    # 完成した差し替えリストをCSVファイルとして出力しています。
    # index=Falseは、データフレームのインデックスをCSVに書き込まないようにしています。
    # encoding='cp932'は、Excelで開いた時に文字化けしないためのエンコーディングですが、環境によっては'utf-8-sig'が推奨されます。
    final_df.to_csv(ROOT_DIR / "花王差し替えリスト完成版.csv", index=False, encoding='cp932')

    # Excelファイルとしても出力しています。
    # なぜExcelでも出力するかというと、CSVだと文字化けしたり、見た目が整いにくかったりする場合があるため、利用者が使いやすい形式を提供するためです。
    # engine='openpyxl'は、Excelファイルを読み書きするためのエンジンを指定しています。
    final_df.to_excel(ROOT_DIR / "花王差し替えリスト完成版.xlsx", index=False, engine='openpyxl')

    print("🎉 差し替えリスト作成完了！CSVとExcelに出力しました！")

# スクリプトが直接実行された時だけ、main関数を呼び出すようにしています。
# なぜこの処理を使うかというと、このスクリプトを他のPythonファイルからインポートして使う場合でも、`main`関数が自動で実行されてしまうのを防ぐためです。
if __name__ == '__main__':
    main()