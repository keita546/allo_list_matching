# -*- coding: utf-8 -*-
"""
ç´¯ç©ãƒªã‚¹ãƒˆçµ±åˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ï¼ˆé€±æ¬¡æ›´æ–°å°‚ç”¨ãƒ»å®Œå…¨ç‰ˆv3ï¼‰

ã€ã‚«ãƒ©ãƒ çµ±ä¸€å½¢å¼ã€‘ï¼ˆãƒãƒƒãƒãƒ³ã‚°çµæœã«åˆã‚ã›ã‚‹ï¼‰
- JANã‚³ãƒ¼ãƒ‰_æ—§
- å•†å“åç§°ï¼ˆã‚«ãƒŠï¼‰_æ—§
- JANã‚³ãƒ¼ãƒ‰_æ–°
- å•†å“åç§°ï¼ˆã‚«ãƒŠï¼‰_æ–°
- æ–°JANå‚™è€ƒ
- ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
- æœŸé–“
- å‡¦ç†æ—¥

ã€èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆæ›´æ–°æ™‚ã€‘
ç´¯ç©ã‹ã‚‰å¤ã„èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆéƒ¨åˆ†ã‚’å‰Šé™¤ â†’ æ–°ã—ã„ãƒªã‚¹ãƒˆã‚’è¿½åŠ 

Author: HIBI KEITA
Version: 3.0
"""

import pandas as pd
from pathlib import Path
import tkinter as tk
from tkinter import filedialog, messagebox, simpledialog
from datetime import datetime


# ========================================================================
# ã‚«ãƒ©ãƒ åã®å®šç¾©
# ========================================================================

# å†…éƒ¨å‡¦ç†ç”¨ï¼ˆãƒãƒƒãƒãƒ³ã‚°çµæœã®å½¢å¼ï¼‰
INTERNAL_COLUMNS = {
    'jan_old': 'JANã‚³ãƒ¼ãƒ‰_æ—§',
    'name_old': 'å•†å“åç§°ï¼ˆã‚«ãƒŠï¼‰_æ—§',
    'jan_new': 'JANã‚³ãƒ¼ãƒ‰_æ–°',
    'name_new': 'å•†å“åç§°ï¼ˆã‚«ãƒŠï¼‰_æ–°',
    'note': 'æ–°JANå‚™è€ƒ',
    'source': 'ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹',
    'period': 'æœŸé–“',
    'date': 'å‡¦ç†æ—¥',
}

# æœ€çµ‚å‡ºåŠ›ç”¨ï¼ˆExcel: å…¨ã‚«ãƒ©ãƒ ï¼‰
OUTPUT_COLUMNS_EXCEL = [
    'æ—§JANã‚³ãƒ¼ãƒ‰',
    'æ—§å•†å“å',
    'æ–°JANã‚³ãƒ¼ãƒ‰',
    'æ–°å•†å“å',
    'æ–°JANå‚™è€ƒ',
    'ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹',
    'æœŸé–“',
    'å‡¦ç†æ—¥',
]

# æœ€çµ‚å‡ºåŠ›ç”¨ï¼ˆCSV: ã‚·ã‚¹ãƒ†ãƒ èª­ã¿è¾¼ã¿ç”¨ï¼‰
OUTPUT_COLUMNS_CSV = [
    'æ—§JANã‚³ãƒ¼ãƒ‰',
    'æ—§å•†å“å',
    'æ–°JANã‚³ãƒ¼ãƒ‰',
    'æ–°å•†å“å',
    'æ–°JANå‚™è€ƒ',
]

# å†…éƒ¨â†’å‡ºåŠ›ã®ã‚«ãƒ©ãƒ åå¤‰æ›
OUTPUT_COLUMN_MAPPING = {
    'JANã‚³ãƒ¼ãƒ‰_æ—§': 'æ—§JANã‚³ãƒ¼ãƒ‰',
    'å•†å“åç§°ï¼ˆã‚«ãƒŠï¼‰_æ—§': 'æ—§å•†å“å',
    'JANã‚³ãƒ¼ãƒ‰_æ–°': 'æ–°JANã‚³ãƒ¼ãƒ‰',
    'å•†å“åç§°ï¼ˆã‚«ãƒŠï¼‰_æ–°': 'æ–°å•†å“å',
    'æ–°JANå‚™è€ƒ': 'æ–°JANå‚™è€ƒ',
    'ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹': 'ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹',
    'æœŸé–“': 'æœŸé–“',
    'å‡¦ç†æ—¥': 'å‡¦ç†æ—¥',
}

# ========================================================================
# ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿é–¢æ•°
# ========================================================================

def load_file_flexible(file_path: str) -> pd.DataFrame:
    """CSV/TSV/Excelã‚’è‡ªå‹•åˆ¤åˆ¥ã—ã¦èª­ã¿è¾¼ã¿"""
    p = Path(file_path)
    ext = p.suffix.lower()
    
    print(f"ğŸ“– ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­: {p.name}")
    
    if ext in ['.xlsx', '.xls', '.xlsm']:
        try:
            df = pd.read_excel(file_path, engine='openpyxl', dtype=str)
            print(f"âœ… Excelèª­ã¿è¾¼ã¿æˆåŠŸ")
            return df
        except Exception as e:
            raise ValueError(f"Excelèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    encodings = ['utf-8', 'shift_jis', 'cp932']
    delimiter_map = {'.csv': ',', '.tsv': '\t', '.txt': '\t'}
    
    if ext not in delimiter_map:
        raise ValueError(f"ã‚µãƒãƒ¼ãƒˆå¤–ã®æ‹¡å¼µå­: {ext}")
    
    delimiter = delimiter_map[ext]
    
    for encoding in encodings:
        try:
            df = pd.read_csv(file_path, encoding=encoding, delimiter=delimiter, 
                           on_bad_lines='skip', dtype=str)
            print(f"âœ… {ext}èª­ã¿è¾¼ã¿æˆåŠŸï¼ˆ{encoding}ï¼‰")
            return df
        except UnicodeDecodeError:
            continue
    
    raise UnicodeDecodeError(f"ã™ã¹ã¦ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§èª­ã¿è¾¼ã¿å¤±æ•—")


# ========================================================================
# èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆç”¨æ­£è¦åŒ–ï¼ˆãƒãƒƒãƒãƒ³ã‚°çµæœã®å½¢å¼ã«åˆã‚ã›ã‚‹ï¼‰
# ========================================================================

def normalize_kao_planet(df: pd.DataFrame, file_name: str, period: str) -> pd.DataFrame:
    """
    èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆã®ã‚«ãƒ©ãƒ ã‚’ãƒãƒƒãƒãƒ³ã‚°çµæœå½¢å¼ã«å¤‰æ›
    
    å…¥åŠ›: æ—§JANã‚³ãƒ¼ãƒ‰, æ—§å•†å“å, æ–°JANã‚³ãƒ¼ãƒ‰, æ–°å•†å“å, æ–°JANå‚™è€ƒ
    å‡ºåŠ›: JANã‚³ãƒ¼ãƒ‰_æ—§, å•†å“åç§°ï¼ˆã‚«ãƒŠï¼‰_æ—§, JANã‚³ãƒ¼ãƒ‰_æ–°, å•†å“åç§°ï¼ˆã‚«ãƒŠï¼‰_æ–°, æ–°JANå‚™è€ƒ, ...
    """
    print(f"ğŸ“ èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆæ­£è¦åŒ–ä¸­...")
    
    # ã‚«ãƒ©ãƒ åå¤‰æ›
    column_mapping = {
        'æ—§JANã‚³ãƒ¼ãƒ‰': INTERNAL_COLUMNS['jan_old'],
        'æ—§å•†å“å': INTERNAL_COLUMNS['name_old'],
        'æ–°JANã‚³ãƒ¼ãƒ‰': INTERNAL_COLUMNS['jan_new'],
        'æ–°å•†å“å': INTERNAL_COLUMNS['name_new'],
        'æ–°JANå‚™è€ƒ': INTERNAL_COLUMNS['note'],
    }
    
    df_normalized = df.rename(columns=column_mapping)
    
    # å¿…é ˆã‚«ãƒ©ãƒ ã®è¿½åŠ 
    df_normalized[INTERNAL_COLUMNS['source']] = 'èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆ'
    df_normalized[INTERNAL_COLUMNS['period']] = period
    df_normalized[INTERNAL_COLUMNS['date']] = datetime.now().strftime('%Y-%m-%d')
    
    # æ–°JANå‚™è€ƒãŒãªã„å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…¥ã‚Œã‚‹
    if INTERNAL_COLUMNS['note'] not in df_normalized.columns:
        df_normalized[INTERNAL_COLUMNS['note']] = file_name
    else:
        # ç©ºã®å ´åˆã®ã¿ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…¥ã‚Œã‚‹
        df_normalized[INTERNAL_COLUMNS['note']] = df_normalized[INTERNAL_COLUMNS['note']].fillna(file_name)
    
    # çµ±ä¸€ã‚«ãƒ©ãƒ é †ã«ä¸¦ã³æ›¿ãˆ
    output_cols = list(INTERNAL_COLUMNS.values())
    for col in output_cols:
        if col not in df_normalized.columns:
            df_normalized[col] = ''
    
    df_normalized = df_normalized[output_cols].copy()
    
    print(f"âœ… æ­£è¦åŒ–å®Œäº†: {len(df_normalized)}ä»¶")
    return df_normalized


# ========================================================================
# ãƒãƒƒãƒãƒ³ã‚°çµæœç”¨æ­£è¦åŒ–
# ========================================================================

def normalize_matching(df: pd.DataFrame, file_name: str) -> pd.DataFrame:
    """
    ãƒãƒƒãƒãƒ³ã‚°çµæœã®ã‚«ãƒ©ãƒ ã‚’çµ±ä¸€å½¢å¼ã«å¤‰æ›
    ï¼ˆæ—¢ã«ãƒãƒƒãƒãƒ³ã‚°å½¢å¼ã®ã‚«ãƒ©ãƒ åãªã®ã§ã€è¿½åŠ ã‚«ãƒ©ãƒ ã®ã¿å‡¦ç†ï¼‰
    """
    print(f"ğŸ“ ãƒãƒƒãƒãƒ³ã‚°çµæœæ­£è¦åŒ–ä¸­...")
    
    # æ—¢å­˜ã®ã‚«ãƒ©ãƒ åãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå¿µã®ãŸã‚ï¼‰
    column_mapping = {
        'JANã‚³ãƒ¼ãƒ‰_æ—§': INTERNAL_COLUMNS['jan_old'],
        'å•†å“åç§°ï¼ˆã‚«ãƒŠï¼‰_æ—§': INTERNAL_COLUMNS['name_old'],
        'JANã‚³ãƒ¼ãƒ‰_æ–°': INTERNAL_COLUMNS['jan_new'],
        'å•†å“åç§°ï¼ˆã‚«ãƒŠï¼‰_æ–°': INTERNAL_COLUMNS['name_new'],
    }
    
    df_normalized = df.rename(columns=column_mapping)
    
    # å¿…é ˆã‚«ãƒ©ãƒ ã®è¿½åŠ 
    if INTERNAL_COLUMNS['source'] not in df_normalized.columns:
        df_normalized[INTERNAL_COLUMNS['source']] = 'ãƒãƒƒãƒãƒ³ã‚°'
    
    if INTERNAL_COLUMNS['period'] not in df_normalized.columns:
        df_normalized[INTERNAL_COLUMNS['period']] = ''
    
    if INTERNAL_COLUMNS['date'] not in df_normalized.columns:
        df_normalized[INTERNAL_COLUMNS['date']] = datetime.now().strftime('%Y-%m-%d')
    
    if INTERNAL_COLUMNS['note'] not in df_normalized.columns:
        df_normalized[INTERNAL_COLUMNS['note']] = file_name
    
    print(f"âœ… æ­£è¦åŒ–å®Œäº†: {len(df_normalized)}ä»¶")
    return df_normalized


# ========================================================================
# JANã‚³ãƒ¼ãƒ‰ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°
# ========================================================================

def clean_jan_codes(df: pd.DataFrame) -> pd.DataFrame:
    """JANã‚³ãƒ¼ãƒ‰ã‚’13æ¡ã«çµ±ä¸€"""
    print("ğŸ§¹ JANã‚³ãƒ¼ãƒ‰ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ä¸­...")
    
    jan_cols = [INTERNAL_COLUMNS['jan_old'], INTERNAL_COLUMNS['jan_new']]
    
    for col in jan_cols:
        if col in df.columns:
            df[col] = (df[col].astype(str)
                      .str.replace(r'\D+', '', regex=True)
                      .str.zfill(13)
                      .str[:13])
    
    print("âœ… ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°å®Œäº†")
    return df


# ========================================================================
# ç´¯ç©ã‹ã‚‰å¤ã„èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
# ========================================================================

def remove_old_kao_planet(existing_df: pd.DataFrame, periods_to_keep: list) -> pd.DataFrame:
    """
    ç´¯ç©ãƒªã‚¹ãƒˆã‹ã‚‰æŒ‡å®šæœŸé–“ä»¥å¤–ã®èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
    
    Args:
        existing_df: æ—¢å­˜ã®ç´¯ç©ãƒªã‚¹ãƒˆ
        periods_to_keep: ä¿æŒã™ã‚‹æœŸé–“ã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: ["24å¹´ä¸‹", "25å¹´ä¸Š"]ï¼‰
    
    Returns:
        å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ãŸç´¯ç©ãƒªã‚¹ãƒˆ
    """
    if existing_df.empty:
        return existing_df
    
    source_col = UNIFIED_COLUMNS['source']
    period_col = UNIFIED_COLUMNS['period']
    
    if source_col not in existing_df.columns or period_col not in existing_df.columns:
        print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹/æœŸé–“åˆ—ãŒãªã„ãŸã‚ã€å‰Šé™¤å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—")
        return existing_df
    
    print(f"ğŸ—‘ï¸ å¤ã„èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ä¸­...")
    print(f"   ä¿æŒã™ã‚‹æœŸé–“: {periods_to_keep}")
    
    # èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆä»¥å¤–ã®ãƒ‡ãƒ¼ã‚¿ã¯ãã®ã¾ã¾ä¿æŒ
    non_kao_planet = existing_df[
        ~existing_df[source_col].str.contains('èŠ±ç‹|ãƒ—ãƒ©ãƒãƒƒãƒˆ', case=False, na=False, regex=True)
    ]
    
    # èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆã§ä¿æŒã™ã‚‹æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿
    kao_planet_keep = existing_df[
        existing_df[source_col].str.contains('èŠ±ç‹|ãƒ—ãƒ©ãƒãƒƒãƒˆ', case=False, na=False, regex=True) &
        existing_df[period_col].isin(periods_to_keep)
    ]
    
    # å‰Šé™¤ã•ã‚Œã‚‹ä»¶æ•°ã‚’è¨ˆç®—
    kao_planet_all = existing_df[
        existing_df[source_col].str.contains('èŠ±ç‹|ãƒ—ãƒ©ãƒãƒƒãƒˆ', case=False, na=False, regex=True)
    ]
    removed_count = len(kao_planet_all) - len(kao_planet_keep)
    
    if removed_count > 0:
        print(f"   å‰Šé™¤: {removed_count}ä»¶")
    
    result = pd.concat([non_kao_planet, kao_planet_keep], ignore_index=True)
    print(f"âœ… å‰Šé™¤å¾Œ: {len(result)}ä»¶")
    
    return result


# ========================================================================
# é‡è¤‡å‰Šé™¤é–¢æ•°ï¼ˆå®Œå…¨ç‰ˆï¼‰
# ========================================================================

def remove_duplicates_advanced(existing_df: pd.DataFrame, 
                               kao_planet_df: pd.DataFrame, 
                               matching_df: pd.DataFrame) -> pd.DataFrame:
    """
    3æ®µéšã®å„ªå…ˆé †ä½ä»˜ãé‡è¤‡å‰Šé™¤
    
    å„ªå…ˆé †ä½: ç´¯ç©ï¼ˆæ—¢å­˜ï¼‰ > èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆ > ãƒãƒƒãƒãƒ³ã‚°
    """
    print("\nğŸ“¦ ãƒ‡ãƒ¼ã‚¿çµ±åˆãƒ»é‡è¤‡å‰Šé™¤é–‹å§‹...")
    
    jan_old = UNIFIED_COLUMNS['jan_old']
    jan_new = UNIFIED_COLUMNS['jan_new']
    source_col = UNIFIED_COLUMNS['source']
    
    print(f"  ç´¯ç©ãƒ‡ãƒ¼ã‚¿: {len(existing_df)}ä»¶")
    print(f"  èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆï¼ˆä»Šé€±ï¼‰: {len(kao_planet_df)}ä»¶")
    print(f"  ãƒãƒƒãƒãƒ³ã‚°ï¼ˆä»Šé€±ï¼‰: {len(matching_df)}ä»¶")
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: ç´¯ç©å†…ã®èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆç”±æ¥JANã‚’æŠ½å‡º
    existing_kao_planet_jans = set()
    if not existing_df.empty and source_col in existing_df.columns:
        kao_planet_rows = existing_df[
            existing_df[source_col].str.contains('èŠ±ç‹|ãƒ—ãƒ©ãƒãƒƒãƒˆ', case=False, na=False, regex=True)
        ]
        existing_kao_planet_jans = set(kao_planet_rows[jan_new].dropna())
        print(f"  ç´¯ç©å†…ã®èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆç”±æ¥JAN: {len(existing_kao_planet_jans)}ä»¶")
    
    # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒãƒƒãƒãƒ³ã‚°çµæœã‹ã‚‰ç´¯ç©å†…èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆé‡è¤‡ã‚’å‰Šé™¤
    if not matching_df.empty and existing_kao_planet_jans:
        before = len(matching_df)
        matching_df = matching_df[~matching_df[jan_new].isin(existing_kao_planet_jans)].copy()
        removed = before - len(matching_df)
        if removed > 0:
            print(f"  âœ‚ï¸ ãƒãƒƒãƒãƒ³ã‚°â†’ç´¯ç©å†…èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆé‡è¤‡å‰Šé™¤: {removed}ä»¶")
    
    # ã‚¹ãƒ†ãƒƒãƒ—3: ä»Šé€±ã®èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆã¨ãƒãƒƒãƒãƒ³ã‚°ã®é‡è¤‡å‰Šé™¤
    if not kao_planet_df.empty and not matching_df.empty:
        kao_planet_old_jans = set(kao_planet_df[jan_old].dropna())
        kao_planet_new_jans = set(kao_planet_df[jan_new].dropna())
        
        before = len(matching_df)
        matching_df = matching_df[~matching_df[jan_new].isin(kao_planet_new_jans)].copy()
        matching_df = matching_df[~matching_df[jan_old].isin(kao_planet_old_jans)].copy()
        removed = before - len(matching_df)
        if removed > 0:
            print(f"  âœ‚ï¸ ãƒãƒƒãƒãƒ³ã‚°â†’ä»Šé€±èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆé‡è¤‡å‰Šé™¤: {removed}ä»¶")
    
    # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ‡ãƒ¼ã‚¿çµåˆï¼ˆå„ªå…ˆé †ä½é †ï¼‰
    all_data = pd.concat([existing_df, kao_planet_df, matching_df], ignore_index=True)
    print(f"  çµ±åˆå¾Œ: {len(all_data)}ä»¶")
    
    # ã‚¹ãƒ†ãƒƒãƒ—5: æ–°JANã§é‡è¤‡å‰Šé™¤
    before = len(all_data)
    all_data = all_data.drop_duplicates(subset=[jan_new], keep='first')
    removed = before - len(all_data)
    if removed > 0:
        print(f"  ğŸ—‘ï¸ æ–°JANé‡è¤‡å‰Šé™¤: {removed}ä»¶")
    
    # ã‚¹ãƒ†ãƒƒãƒ—6: æ—§JAN=æ–°JANã®ã‚‚ã®ã‚’å‰Šé™¤
    before = len(all_data)
    all_data = all_data[all_data[jan_old] != all_data[jan_new]].copy()
    removed = before - len(all_data)
    if removed > 0:
        print(f"  ğŸ”„ åŒä¸€JANå‰Šé™¤: {removed}ä»¶")
    
    print(f"  âœ… æœ€çµ‚ä»¶æ•°: {len(all_data)}ä»¶")
    return all_data


# ========================================================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ========================================================================

def main():
    print("=" * 60)
    print("ç´¯ç©ãƒªã‚¹ãƒˆçµ±åˆãƒ—ãƒ­ã‚°ãƒ©ãƒ  - é€±æ¬¡æ›´æ–°ï¼ˆv3ï¼‰")
    print("=" * 60)
    
    # ========== ã‚¹ãƒ†ãƒƒãƒ—1: ç´¯ç©ãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿ ==========
    print("\nã€ã‚¹ãƒ†ãƒƒãƒ—1ã€‘ç´¯ç©ãƒªã‚¹ãƒˆã®èª­ã¿è¾¼ã¿")
    
    root = tk.Tk()
    root.withdraw()
    
    existing_df = pd.DataFrame()
    
    if messagebox.askyesno("ç´¯ç©ãƒªã‚¹ãƒˆ", "å‰é€±ã®ç´¯ç©ãƒªã‚¹ãƒˆãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ\nï¼ˆåˆå›ã¯ã€Œã„ã„ãˆã€ï¼‰"):
        existing_path = filedialog.askopenfilename(
            title="å‰é€±ã®ç´¯ç©ãƒªã‚¹ãƒˆã‚’é¸æŠ",
            filetypes=[("Excel/CSV", "*.xlsx *.csv"), ("ã™ã¹ã¦", "*.*")]
        )
        
        if existing_path:
            try:
                existing_df = load_file_flexible(existing_path)
                existing_df = clean_jan_codes(existing_df)
                print(f"âœ… ç´¯ç©ãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿: {len(existing_df)}ä»¶")
            except Exception as e:
                messagebox.showerror("ã‚¨ãƒ©ãƒ¼", f"ç´¯ç©ãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿å¤±æ•—:\n{e}")
                root.destroy()
                return
    else:
        print("ğŸ“‚ æ–°è¦ä½œæˆãƒ¢ãƒ¼ãƒ‰")
    
    root.destroy()
    
    # ========== ã‚¹ãƒ†ãƒƒãƒ—2: ãƒãƒƒãƒãƒ³ã‚°çµæœèª­ã¿è¾¼ã¿ ==========
    print("\nã€ã‚¹ãƒ†ãƒƒãƒ—2ã€‘ãƒãƒƒãƒãƒ³ã‚°çµæœã®èª­ã¿è¾¼ã¿")
    
    root = tk.Tk()
    root.withdraw()
    
    messagebox.showinfo("é¸æŠ", "ä»Šé€±ã®ãƒãƒƒãƒãƒ³ã‚°çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
    
    matching_path = filedialog.askopenfilename(
        title="ãƒãƒƒãƒãƒ³ã‚°çµæœã‚’é¸æŠ",
        filetypes=[("Excel/CSV", "*.xlsx *.csv *.tsv"), ("ã™ã¹ã¦", "*.*")]
    )
    
    root.destroy()
    
    if not matching_path:
        messagebox.showwarning("ã‚­ãƒ£ãƒ³ã‚»ãƒ«", "ãƒãƒƒãƒãƒ³ã‚°çµæœãŒé¸æŠã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    try:
        matching_df = load_file_flexible(matching_path)
        matching_df = normalize_matching(matching_df, Path(matching_path).name)
        matching_df = clean_jan_codes(matching_df)
        print(f"âœ… ãƒãƒƒãƒãƒ³ã‚°çµæœèª­ã¿è¾¼ã¿: {len(matching_df)}ä»¶")
    except Exception as e:
        messagebox.showerror("ã‚¨ãƒ©ãƒ¼", f"ãƒãƒƒãƒãƒ³ã‚°çµæœèª­ã¿è¾¼ã¿å¤±æ•—:\n{e}")
        return
    
    # ========== ã‚¹ãƒ†ãƒƒãƒ—3: èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆå·®ã—æ›¿ãˆãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿ ==========
    print("\nã€ã‚¹ãƒ†ãƒƒãƒ—3ã€‘èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆå·®ã—æ›¿ãˆãƒªã‚¹ãƒˆã®èª­ã¿è¾¼ã¿")
    
    root = tk.Tk()
    root.withdraw()
    
    kao_planet_df = pd.DataFrame()
    
    choice = messagebox.askquestion(
        "èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆ", 
        "ä»Šé€±ã€èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆã®å·®ã—æ›¿ãˆãƒªã‚¹ãƒˆã‚’æ›´æ–°ã—ã¾ã™ã‹ï¼Ÿ\n"
        "ï¼ˆåŠå¹´ã«1å›ç¨‹åº¦ï¼‰\n\n"
        "ã€Œã¯ã„ã€â†’ æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤\n"
        "ã€Œã„ã„ãˆã€â†’ ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒãƒƒãƒãƒ³ã‚°ã®ã¿çµ±åˆï¼‰"
    )
    
    if choice == 'yes':
        # æœŸé–“å…¥åŠ›
        period = simpledialog.askstring(
            "æœŸé–“å…¥åŠ›",
            "èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆã®æœŸé–“ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„\nï¼ˆä¾‹: 25å¹´ä¸Šã€25å¹´ä¸‹ï¼‰",
            initialvalue="25å¹´ä¸Š"
        )
        
        if not period:
            period = datetime.now().strftime('%Yå¹´')
        
        # ä¿æŒã™ã‚‹æœŸé–“ã‚’å…¥åŠ›
        keep_periods_str = simpledialog.askstring(
            "ä¿æŒæœŸé–“",
            "ç´¯ç©ã‹ã‚‰ä¿æŒã™ã‚‹æœŸé–“ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ›\nï¼ˆä¾‹: 24å¹´ä¸‹,25å¹´ä¸Šï¼‰\n\n"
            "â€»å¤ã„æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã¯å‰Šé™¤ã•ã‚Œã¾ã™\n"
            "â€»ç©ºæ¬„ã§å…¨å‰Šé™¤ã—ã¦ã‹ã‚‰æ–°è¦è¿½åŠ ",
            initialvalue="24å¹´ä¸‹,25å¹´ä¸Š"
        )
        
        if keep_periods_str:
            periods_to_keep = [p.strip() for p in keep_periods_str.split(',')]
        else:
            periods_to_keep = []
        
        # å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
        existing_df = remove_old_kao_planet(existing_df, periods_to_keep)
        
        # æ–°ã—ã„èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        kao_planet_path = filedialog.askopenfilename(
            title="èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆå·®ã—æ›¿ãˆãƒªã‚¹ãƒˆã‚’é¸æŠ",
            filetypes=[("Excel/CSV", "*.xlsx *.csv"), ("ã™ã¹ã¦", "*.*")]
        )
        
        if kao_planet_path:
            try:
                kao_planet_df = load_file_flexible(kao_planet_path)
                kao_planet_df = normalize_kao_planet(
                    kao_planet_df, 
                    Path(kao_planet_path).name,
                    period
                )
                kao_planet_df = clean_jan_codes(kao_planet_df)
                print(f"âœ… èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆèª­ã¿è¾¼ã¿: {len(kao_planet_df)}ä»¶")
            except Exception as e:
                messagebox.showerror("ã‚¨ãƒ©ãƒ¼", f"èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆèª­ã¿è¾¼ã¿å¤±æ•—:\n{e}")
                root.destroy()
                return
    else:
        print("ğŸ“‚ èŠ±ç‹ãƒ»ãƒ—ãƒ©ãƒãƒƒãƒˆãªã—ï¼ˆãƒãƒƒãƒãƒ³ã‚°ã®ã¿çµ±åˆï¼‰")
    
    root.destroy()
    
    # ========== ã‚¹ãƒ†ãƒƒãƒ—4: å‡ºåŠ›å…ˆé¸æŠ ==========
    print("\nã€ã‚¹ãƒ†ãƒƒãƒ—4ã€‘å‡ºåŠ›å…ˆã®é¸æŠ")
    
    root = tk.Tk()
    root.withdraw()
    
    output_dir = filedialog.askdirectory(title="ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠ")
    
    root.destroy()
    
    if not output_dir:
        messagebox.showwarning("ã‚­ãƒ£ãƒ³ã‚»ãƒ«", "ä¿å­˜å…ˆãŒé¸æŠã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    output_dir = Path(output_dir)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_csv = output_dir / f"ç´¯ç©_å·®ã—æ›¿ãˆãƒªã‚¹ãƒˆ_{timestamp}.csv"
    output_excel = output_dir / f"ç´¯ç©_å·®ã—æ›¿ãˆãƒªã‚¹ãƒˆ_{timestamp}.xlsx"
    latest_csv = output_dir / "ç´¯ç©_å·®ã—æ›¿ãˆãƒªã‚¹ãƒˆ_æœ€æ–°.csv"
    latest_excel = output_dir / "ç´¯ç©_å·®ã—æ›¿ãˆãƒªã‚¹ãƒˆ_æœ€æ–°.xlsx"
    
    # ========== ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ‡ãƒ¼ã‚¿çµ±åˆ ==========
    print("\nã€ã‚¹ãƒ†ãƒƒãƒ—5ã€‘ãƒ‡ãƒ¼ã‚¿çµ±åˆãƒ»é‡è¤‡å‰Šé™¤")
    
    final_df = remove_duplicates_advanced(existing_df, kao_planet_df, matching_df)
    
    # ========== ã‚¹ãƒ†ãƒƒãƒ—6: ä¿å­˜ ==========
    print("\nã€ã‚¹ãƒ†ãƒƒãƒ—6ã€‘ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜")
    
    try:
        print(f"ğŸ’¾ CSVä¿å­˜ä¸­ï¼ˆcp932ï¼‰: {output_csv.name}")
        final_df.to_csv(output_csv, index=False, encoding='cp932', errors='replace')
        final_df.to_csv(latest_csv, index=False, encoding='cp932', errors='replace')
        
        print(f"ğŸ’¾ Excelä¿å­˜ä¸­: {output_excel.name}")
        final_df.to_excel(output_excel, index=False, engine='openpyxl')
        final_df.to_excel(latest_excel, index=False, engine='openpyxl')
        
        print("âœ… ä¿å­˜å®Œäº†")
    except Exception as e:
        messagebox.showerror("ã‚¨ãƒ©ãƒ¼", f"ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å¤±æ•—:\n{e}")
        return
    
    # ========== å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ ==========
    source_col = UNIFIED_COLUMNS['source']
    source_counts = final_df[source_col].value_counts().to_dict() if source_col in final_df.columns else {}
    
    summary = f"""
ğŸ‰ çµ±åˆå‡¦ç†å®Œäº†ï¼

ã€ç´¯ç©ãƒ‡ãƒ¼ã‚¿ã€‘
ç·ä»¶æ•°: {len(final_df)}ä»¶

ã€ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¥ã€‘
{chr(10).join([f'  {k}: {v}ä»¶' for k, v in source_counts.items()])}

ã€ä¿å­˜å…ˆã€‘
ğŸ“ {output_dir}

ã€ãƒ•ã‚¡ã‚¤ãƒ«ã€‘
- {output_csv.name}
- {output_excel.name}
- ç´¯ç©_å·®ã—æ›¿ãˆãƒªã‚¹ãƒˆ_æœ€æ–°.csv/xlsx
"""
    
    print(summary)
    messagebox.showinfo("å®Œäº†", summary)

# ========================================================================
# å®Ÿè¡Œ
# ========================================================================

if __name__ == "__main__":
    main()